{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realistic Cross-View Image Geo-Localization\n",
    "\n",
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "ROOT = '/content/gdrive'\n",
    "drive.mount(ROOT, force_remount=True)\n",
    "\n",
    "# Edit the following variables:\n",
    "MY_GOOGLE_DRIVE_PATH = 'My Drive/adl4cv/Realistic-Cross-View-Image-Geo-Localization' \n",
    "GIT_USERNAME = \"Notram1\" \n",
    "GIT_TOKEN = \"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\"  # GitHub / Settings / Developer settings / Personal access tokens / repo\n",
    "GIT_REPOSITORY = \"Realistic-Cross-View-Image-Geo-Localization\"\n",
    "\n",
    "import os\n",
    "PROJECT_PATH = os.path.join(ROOT, MY_GOOGLE_DRIVE_PATH)\n",
    "GIT_PATH = \"https://\" + GIT_TOKEN + \"@github.com/\" + GIT_USERNAME + \"/\" + GIT_REPOSITORY + \".git\"\n",
    "\n",
    "#!mkdir \"{PROJECT_PATH}\" # Create folder in case you have not done that already\n",
    "%cd \"{PROJECT_PATH}\"    # Change directory to the location defined in project_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone repo to Google Drive or pull latest changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"{PROJECT_PATH}\"    # Change directory to the location defined in project_path\n",
    "# !git clone \"{GIT_PATH}\" # clone the github repository\n",
    "# !git pull origin main # pull latest changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to your branch\n",
    "!git checkout <your_branch>\n",
    "!git status\n",
    "\n",
    "# Change your identity\n",
    "!git config --local user.email \"marton.szep@tum.de\"\n",
    "!git config --local user.name \"Marton Szep\"\n",
    "#!git config --list --show-origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General packages\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "\n",
    "# Modeling packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from data.custom_transforms import *\n",
    "from data.cvusa_utils import CVUSA\n",
    "from networks.c_gan import define_G, define_D, define_R\n",
    "from utils import parser, rgan_wrapper\n",
    "from utils.setup_helper import make_deterministic, get_sys_mem\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (4.0, 3.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rc('xtick', labelsize=12)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=12)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=10)    # legend fontsize\n",
    "\n",
    "# for auto-reloading external modules see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse = parser.Parser()\n",
    "opt, log_file = parse.parse()\n",
    "opt.is_Train = True\n",
    "make_deterministic(opt.seed)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(x) for x in opt.gpu_ids)\n",
    "log = open(log_file, 'a')\n",
    "log_print = lambda ms: parse.log(ms, log)\n",
    "\n",
    "#define networks\n",
    "generator = define_G(netG=opt.g_model, gpu_ids=opt.gpu_ids)\n",
    "log_print('Init {} as generator model'.format(opt.g_model))\n",
    "\n",
    "discriminator = define_D(input_c=opt.input_c, output_c=opt.realout_c, ndf=opt.feature_c, netD=opt.d_model,\n",
    "                            condition=opt.condition, n_layers_D=opt.n_layers, gpu_ids=opt.gpu_ids)\n",
    "log_print('Init {} as discriminator model'.format(opt.d_model))\n",
    "\n",
    "retrieval = define_R(ret_method=opt.r_model, polar=opt.polar, gpu_ids=opt.gpu_ids)\n",
    "log_print('Init {} as retrieval model'.format(opt.r_model))\n",
    "\n",
    "rgan_wrapper = rgan_wrapper.RGANWrapper(opt, log_file, generator, discriminator, retrieval)\n",
    "\n",
    "# Configure data loader\n",
    "composed_transforms = transforms.Compose([RandomHorizontalFlip(),\n",
    "                                            ToTensor()])\n",
    "train_dataset = CVUSA(root=opt.data_root, csv_file=opt.train_csv, use_polar=opt.polar, name=opt.name,\n",
    "                    transform_op=composed_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=opt.batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CVUSA(root=opt.data_root, csv_file=opt.val_csv, use_polar=opt.polar, name=opt.name,\n",
    "                    transform_op=ToTensor())\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=opt.batch_size, shuffle=False, num_workers=0)\n",
    "log_print('Load datasets from {}: train_set={} val_set={}'.format(opt.data_root, len(train_dataset), len(val_dataset)))\n",
    "\n",
    "ret_best_acc = rgan_wrapper.ret_best_acc\n",
    "log_print('Start training from epoch {} to {}, best acc: {}'.format(opt.start_epoch, opt.n_epochs, ret_best_acc))\n",
    "for epoch in range(opt.start_epoch, opt.n_epochs):\n",
    "    start_time = time.time()\n",
    "    batches_done = 0\n",
    "    val_batches_done = 0\n",
    "    street_batches_t = []\n",
    "    fake_street_batches_t = []\n",
    "    street_batches_v = []\n",
    "    fake_street_batches_v = []\n",
    "    epoch_retrieval_loss = []\n",
    "    epoch_generator_loss = []\n",
    "    epoch_discriminator_loss = []\n",
    "    log_print('>>> RGAN Epoch {}'.format(epoch))\n",
    "    rgan_wrapper.generator.train()\n",
    "    rgan_wrapper.discriminator.train()\n",
    "    rgan_wrapper.retrieval.train()\n",
    "    for i, data in enumerate(train_loader):  # inner loop within one epoch\n",
    "\n",
    "        rgan_wrapper.set_input(data)\n",
    "        rgan_wrapper.optimize_parameters(epoch)\n",
    "\n",
    "        fake_street_batches_t.append(rgan_wrapper.fake_street_out.cpu().data)\n",
    "        street_batches_t.append(rgan_wrapper.street_out.cpu().data)\n",
    "        epoch_retrieval_loss.append(rgan_wrapper.r_loss.item())\n",
    "        epoch_discriminator_loss.append(rgan_wrapper.d_loss.item())\n",
    "        epoch_generator_loss.append(rgan_wrapper.g_loss.item())\n",
    "\n",
    "        if (i + 1) % 40 == 0 or (i + 1) == len(train_loader):\n",
    "            fake_street_vec = torch.cat(fake_street_batches_t, dim=0)\n",
    "            street_vec = torch.cat(street_batches_t, dim=0)\n",
    "            dists = 2 - 2 * torch.matmul(fake_street_vec, street_vec.permute(1, 0))\n",
    "            tp1 = rgan_wrapper.mutual_topk_acc(dists, topk=1)\n",
    "            tp5 = rgan_wrapper.mutual_topk_acc(dists, topk=5)\n",
    "            tp10 = rgan_wrapper.mutual_topk_acc(dists, topk=10)\n",
    "            log_print('Batch:{} loss={:.3f} samples:{} tp1={tp1[0]:.2f}/{tp1[1]:.2f} ' \\\n",
    "                    'tp5={tp5[0]:.2f}/{tp5[1]:.2f}'.format(i + 1, np.mean(epoch_retrieval_loss),\n",
    "                                                            len(dists), tp1=tp1, tp5=tp5))\n",
    "            street_batches_t.clear()\n",
    "            fake_street_batches_t.clear()\n",
    "\n",
    "    rgan_wrapper.save_networks(epoch, os.path.dirname(log_file), best_acc=ret_best_acc,\n",
    "                                    last_ckpt=True)  # Always save last ckpt\n",
    "\n",
    "\n",
    "    # Save model periodically\n",
    "    if (epoch + 1) % opt.save_step == 0:\n",
    "        rgan_wrapper.save_networks(epoch, os.path.dirname(log_file), best_acc=ret_best_acc)\n",
    "\n",
    "    rgan_wrapper.generator.eval()\n",
    "    rgan_wrapper.retrieval.eval()\n",
    "    for i, data in enumerate(val_loader):\n",
    "        rgan_wrapper.set_input(data)\n",
    "        rgan_wrapper.eval_model()\n",
    "        fake_street_batches_v.append(rgan_wrapper.fake_street_out_val.cpu().data)\n",
    "        street_batches_v.append(rgan_wrapper.street_out_val.cpu().data)\n",
    "\n",
    "\n",
    "    fake_street_vec = torch.cat(fake_street_batches_v, dim=0)\n",
    "    street_vec = torch.cat(street_batches_v, dim=0)\n",
    "    dists = 2 - 2 * torch.matmul(fake_street_vec, street_vec.permute(1, 0))\n",
    "    tp1 = rgan_wrapper.mutual_topk_acc(dists, topk=1)\n",
    "    tp5 = rgan_wrapper.mutual_topk_acc(dists, topk=5)\n",
    "    tp10 = rgan_wrapper.mutual_topk_acc(dists, topk=10)\n",
    "\n",
    "    num = len(dists)\n",
    "    tp1p = rgan_wrapper.mutual_topk_acc(dists, topk=0.01 * num)\n",
    "    acc = Namespace(num=len(dists), tp1=tp1, tp5=tp5, tp10=tp10, tp1p=tp1p)\n",
    "\n",
    "    log_print('\\nEvaluate Samples:{num:d}\\nRecall(p2s/s2p) tp1:{tp1[0]:.2f}/{tp1[1]:.2f} ' \\\n",
    "                'tp5:{tp5[0]:.2f}/{tp5[1]:.2f} tp10:{tp10[0]:.2f}/{tp10[1]:.2f} ' \\\n",
    "                'tp1%:{tp1p[0]:.2f}/{tp1p[1]:.2f}'.format(epoch + 1, num=acc.num, tp1=acc.tp1,\n",
    "                                                        tp5=acc.tp5, tp10=acc.tp10, tp1p=acc.tp1p))\n",
    "\n",
    "    # Save the best model\n",
    "    tp1_p2s_acc = acc.tp1[0]\n",
    "    if tp1_p2s_acc > ret_best_acc:\n",
    "        ret_best_acc = tp1_p2s_acc\n",
    "        rgan_wrapper.save_networks(epoch, os.path.dirname(log_file), best_acc=ret_best_acc, is_best=True)\n",
    "        log_print('>>Save best model: epoch={} best_acc(tp1_p2s):{:.2f}'.format(epoch + 1, tp1_p2s_acc))\n",
    "\n",
    "    # Progam stastics\n",
    "    rss, vms = get_sys_mem()\n",
    "    log_print('Memory usage: rss={:.2f}GB vms={:.2f}GB Time:{:.2f}s'.format(rss, vms, time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse = parser.Parser()\n",
    "opt, log_file = parse.parse()\n",
    "opt.is_Train = True\n",
    "make_deterministic(opt.seed)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(x) for x in opt.gpu_ids)\n",
    "\n",
    "log = open(log_file, 'a')\n",
    "log_print = lambda ms: parse.log(ms, log)\n",
    "\n",
    "#define networks\n",
    "generator = define_G(netG=opt.g_model, gpu_ids=opt.gpu_ids)\n",
    "print('Init {} as generator model'.format(opt.g_model))\n",
    "\n",
    "discriminator = define_D(input_c=opt.input_c, output_c=opt.realout_c, ndf=opt.feature_c, netD=opt.d_model,\n",
    "                            condition=opt.condition, n_layers_D=opt.n_layers, gpu_ids=opt.gpu_ids)\n",
    "print('Init {} as discriminator model'.format(opt.d_model))\n",
    "\n",
    "retrieval = define_R(ret_method=opt.r_model, polar=opt.polar, gpu_ids=opt.gpu_ids)\n",
    "print('Init {} as retrieval model'.format(opt.r_model))\n",
    "\n",
    "# Initialize network wrapper\n",
    "if opt.resume:\n",
    "    opt.rgan_checkpoint = os.path.join('./placeholder_checkpoint_path', 'rgan_best_ckpt.pth')\n",
    "\n",
    "rgan_wrapper = rgan_wrapper.RGANWrapper(opt, log_file, generator, discriminator, retrieval)\n",
    "# Configure data loader\n",
    "val_dataset = CVUSA(root=opt.data_root, csv_file=opt.val_csv, use_polar=opt.polar, name=opt.name,\n",
    "                    transform_op=ToTensor())\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=opt.batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "log_print('Load test dataset from {}: val_set={}'.format(opt.data_root, len(val_dataset)))\n",
    "log_print('length of val loader: {:d}'.format(len(val_loader)))\n",
    "\n",
    "rgan_wrapper.generator.eval()\n",
    "rgan_wrapper.retrieval.eval()\n",
    "fake_street_batches_v = []\n",
    "street_batches_v = []\n",
    "item_ids = []\n",
    "\n",
    "for i, data in enumerate(val_loader):\n",
    "    print (i)\n",
    "    rgan_wrapper.set_input(data)\n",
    "    rgan_wrapper.eval_model()\n",
    "    fake_street_batches_v.append(rgan_wrapper.fake_street_out_val.cpu().data)\n",
    "    street_batches_v.append(rgan_wrapper.street_out_val.cpu().data)\n",
    "\n",
    "fake_street_vec = torch.cat(fake_street_batches_v, dim=0)\n",
    "street_vec = torch.cat(street_batches_v, dim=0)\n",
    "dists = 2 - 2 * torch.matmul(fake_street_vec, street_vec.permute(1, 0))\n",
    "\n",
    "tp1 = rgan_wrapper.mutual_topk_acc(dists, topk=1)\n",
    "tp5 = rgan_wrapper.mutual_topk_acc(dists, topk=5)\n",
    "tp10 = rgan_wrapper.mutual_topk_acc(dists, topk=10)\n",
    "\n",
    "num = len(dists)\n",
    "tp1p = rgan_wrapper.mutual_topk_acc(dists, topk=0.01 * num)\n",
    "acc = Namespace(num=len(dists), tp1=tp1, tp5=tp5, tp10=tp10, tp1p=tp1p)\n",
    "\n",
    "log_print('\\nEvaluate Samples:{num:d}\\nRecall(p2s/s2p) tp1:{tp1[0]:.2f}/{tp1[1]:.2f} ' \\\n",
    "        'tp5:{tp5[0]:.2f}/{tp5[1]:.2f} tp10:{tp10[0]:.2f}/{tp10[1]:.2f} ' \\\n",
    "        'tp1%:{tp1p[0]:.2f}/{tp1p[1]:.2f}'.format(1, num=acc.num, tp1=acc.tp1,\n",
    "                                                tp5=acc.tp5, tp10=acc.tp10, tp1p=acc.tp1p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save changes to GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add / track changed files\n",
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit changes (don't forget to change the message!)\n",
    "!git commit -m \"commit message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push changes to GitHub repo\n",
    "!git push origin <your_branch>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61708550d29787ebe54bd80c3175f8c01b7f5d506e2711114f96db2fbfcf0d5a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('trivago': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
