{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[]},"interpreter":{"hash":"61708550d29787ebe54bd80c3175f8c01b7f5d506e2711114f96db2fbfcf0d5a"},"kernelspec":{"display_name":"Python 3.7.11 64-bit ('trivago': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jEwQiwOhIA4T"},"source":["# Realistic Cross-View Image Geo-Localization\n","_adjusted to GPU_\n"]},{"cell_type":"markdown","metadata":{"id":"tKruJK0TJzTn"},"source":["### Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zG49rimKTmBW","executionInfo":{"status":"ok","timestamp":1639235898384,"user_tz":-60,"elapsed":2230,"user":{"displayName":"Silent Storm","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18222167859692415426"}},"outputId":"3956cee8-25df-4e53-88d9-0609f1b443a3"},"source":["from google.colab import drive\n","import os\n","\n","ROOT = '/content/gdrive'\n","drive.mount(ROOT) # mount drive\n","\n","%cd \"/content/gdrive/MyDrive/adl4cv/Realistic-Cross-View-Image-Geo-Localization/\""],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","/content/gdrive/MyDrive/adl4cv/Realistic-Cross-View-Image-Geo-Localization\n"]}]},{"cell_type":"markdown","metadata":{"id":"8NQibrRSIA4h"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"Uvbf7N5KIA4i","executionInfo":{"status":"ok","timestamp":1639235901217,"user_tz":-60,"elapsed":1115,"user":{"displayName":"Silent Storm","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18222167859692415426"}}},"source":["# General packages\n","import time\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from argparse import Namespace\n","\n","# Modeling packages\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (4.0, 3.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","plt.rc('xtick', labelsize=12)    # fontsize of the tick labels\n","plt.rc('ytick', labelsize=12)    # fontsize of the tick labels\n","plt.rc('legend', fontsize=10)    # legend fontsize\n","\n","# for auto-reloading external modules see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"cGKiZTs_7tQY"},"source":["# inspect data\n","# PATH_TO_DATA_DIR = \"/content/gdrive/MyDrive/Cross_view_geo_localization/CVUSA\"\n","# sys.path.append(PATH_TO_DATA_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ALEvBUUmOPAP"},"source":["### Prepare data"]},{"cell_type":"code","metadata":{"id":"D548GohrORoG"},"source":["# from data/convert_polar.py\n","############################ Apply Polar Transform to Aerial Images in CVUSA Dataset ############################\n","from data.convert_polar import polar_transform_CVUSA\n","\n","# if os.listdir produces a timeout (colab does that after 2 min), then just try again and again (8-10 times even), it will work eventually\n","# https://stackoverflow.com/questions/54973331/input-output-error-while-using-google-colab-with-google-drive\n","# as suggested on stackoverflow, you can check the following command too\n","# !ls '../CVUSA/bingmap/19/' | grep \"0044417\"\n","# to see if a file can be found or not, if this does not work, probably os.listdir will not either\n","\n","# takes approx. 4 hours\n","# polar_transform_CVUSA(input_dir = '../CVUSA/bingmap/19/', output_dir = '../CVUSA/polarmap/')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2vvyILFokfwd"},"source":["print(len(os.listdir('data/CVUSA/polarmap/')))\n","print(len(os.listdir('data/CVUSA/bingmap/19/')))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uui_bNTuIA4k"},"source":["### Train model "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lihbKB4HqHyL","executionInfo":{"status":"ok","timestamp":1639235903047,"user_tz":-60,"elapsed":655,"user":{"displayName":"Silent Storm","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18222167859692415426"}},"outputId":"77c18fb7-6724-4cd5-a2c0-662c1fc5f8a1"},"source":["# flush out allocated gpu memory\n","# as for some reason it \"stucks\" in if you tried to allocate too much\n","# factory reset runtime would be needed if this does not work\n","import gc\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","# check allocated gpu memory\n","!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Dec 11 15:18:21 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   72C    P8    36W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kuB3MZeaIA4l","outputId":"a6045515-02ad-473a-c2b1-0577f582ebac","executionInfo":{"status":"ok","timestamp":1639236154663,"user_tz":-60,"elapsed":40552,"user":{"displayName":"Silent Storm","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18222167859692415426"}}},"source":["# these imports are here so that they are reloaded always when this cell is run, as these imports might be frequently modified\n","from data.custom_transforms import *\n","from data.cvusa_utils import CVUSA\n","from networks.c_gan import define_G, define_D, define_R\n","from utils import rgan_wrapper, base_wrapper, parser\n","from utils.setup_helper import make_deterministic, get_sys_mem\n","\n","parse = parser.Parser()\n","opt, log_file = parse.parse()\n","opt.is_Train = True\n","make_deterministic(opt.seed)\n","os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(x) for x in opt.gpu_ids)\n","log = open(log_file, 'a')\n","log_print = lambda ms: parse.log(ms, log)\n","\n","#define networks\n","\n","# generator = define_G(netG=opt.g_model, gpu_ids=opt.gpu_ids)\n","# log_print('Init {} as generator model'.format(opt.g_model))\n","\n","# discriminator = define_D(input_c=opt.input_c, output_c=opt.realout_c, ndf=opt.feature_c, netD=opt.d_model,\n","#                             condition=opt.condition, n_layers_D=opt.n_layers, gpu_ids=opt.gpu_ids)\n","# log_print('Init {} as discriminator model'.format(opt.d_model))\n","\n","retrieval = define_R(ret_method=opt.r_model, polar=opt.polar, gpu_ids=opt.gpu_ids)\n","log_print('Init {} as retrieval model'.format(opt.r_model))\n","\n","rgan_wrapper = rgan_wrapper.RGANWrapper(opt, log_file, retrieval)\n","\n","# Configure data loader\n","composed_transforms = transforms.Compose([RandomHorizontalFlip(),\n","                                            ToTensor()])\n","train_dataset = CVUSA(root=opt.data_root, csv_file=opt.train_csv, use_polar=opt.polar, name=opt.name,\n","                    transform_op=composed_transforms, load_pickle=True)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=opt.batch_size, shuffle=True, num_workers=0)\n","\n","val_dataset = CVUSA(root=opt.data_root, csv_file=opt.val_csv, use_polar=opt.polar, name=opt.name,\n","                    transform_op=ToTensor(), load_pickle=True)\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=opt.batch_size, shuffle=False, num_workers=0)\n","log_print('Load datasets from {}: train_set={} val_set={}'.format(opt.data_root, len(train_dataset), len(val_dataset)))\n","\n","ret_best_acc = rgan_wrapper.ret_best_acc\n","log_print('Start training from epoch {} to {}, best acc: {}'.format(opt.start_epoch, opt.n_epochs, ret_best_acc))\n","for epoch in range(opt.start_epoch, opt.n_epochs):\n","    start_time = time.time()\n","    batches_done = 0\n","    val_batches_done = 0\n","    street_batches_t = []\n","    fake_street_batches_t = []\n","    street_batches_v = []\n","    fake_street_batches_v = []\n","    epoch_retrieval_loss = []\n","    epoch_generator_loss = []\n","    epoch_discriminator_loss = []\n","    log_print('>>> RGAN Epoch {}'.format(epoch))\n","    # rgan_wrapper.generator.train()\n","    # rgan_wrapper.discriminator.train()\n","    rgan_wrapper.retrieval.train()\n","    for i, data in enumerate(train_loader):  # inner loop within one epoch\n","\n","        rgan_wrapper.set_input(data)\n","        rgan_wrapper.optimize_parameters(epoch)\n","\n","        fake_street_batches_t.append(rgan_wrapper.fake_street_out.cpu().data)\n","        street_batches_t.append(rgan_wrapper.street_out.cpu().data)\n","        epoch_retrieval_loss.append(rgan_wrapper.r_loss.item())\n","        # epoch_discriminator_loss.append(rgan_wrapper.d_loss.item())\n","        # epoch_generator_loss.append(rgan_wrapper.g_loss.item())\n","\n","        if (i + 1) % 40 == 0 or (i + 1) == len(train_loader):\n","            fake_street_vec = torch.cat(fake_street_batches_t, dim=0)\n","            street_vec = torch.cat(street_batches_t, dim=0)\n","            dists = 2 - 2 * torch.matmul(fake_street_vec, street_vec.permute(1, 0))\n","            tp1 = rgan_wrapper.mutual_topk_acc(dists, topk=1)\n","            tp5 = rgan_wrapper.mutual_topk_acc(dists, topk=5)\n","            tp10 = rgan_wrapper.mutual_topk_acc(dists, topk=10)\n","            log_print('Batch:{} loss={:.3f} samples:{} tp1={tp1[0]:.2f}/{tp1[1]:.2f} ' \\\n","                    'tp5={tp5[0]:.2f}/{tp5[1]:.2f}'.format(i + 1, np.mean(epoch_retrieval_loss),\n","                                                            len(dists), tp1=tp1, tp5=tp5))\n","            street_batches_t.clear()\n","            fake_street_batches_t.clear()\n","\n","    rgan_wrapper.save_networks(epoch, os.path.dirname(log_file), best_acc=ret_best_acc,\n","                                    last_ckpt=True)  # Always save last ckpt\n","\n","\n","    # Save model periodically\n","    if (epoch + 1) % opt.save_step == 0:\n","        rgan_wrapper.save_networks(epoch, os.path.dirname(log_file), best_acc=ret_best_acc)\n","\n","    # rgan_wrapper.generator.eval()\n","    rgan_wrapper.retrieval.eval()\n","    for i, data in enumerate(val_loader):\n","        rgan_wrapper.set_input(data)\n","        rgan_wrapper.eval_model()\n","        fake_street_batches_v.append(rgan_wrapper.fake_street_out_val.cpu().data)\n","        street_batches_v.append(rgan_wrapper.street_out_val.cpu().data)\n","\n","\n","    fake_street_vec = torch.cat(fake_street_batches_v, dim=0)\n","    street_vec = torch.cat(street_batches_v, dim=0)\n","    dists = 2 - 2 * torch.matmul(fake_street_vec, street_vec.permute(1, 0))\n","    tp1 = rgan_wrapper.mutual_topk_acc(dists, topk=1)\n","    tp5 = rgan_wrapper.mutual_topk_acc(dists, topk=5)\n","    tp10 = rgan_wrapper.mutual_topk_acc(dists, topk=10)\n","\n","    num = len(dists)\n","    tp1p = rgan_wrapper.mutual_topk_acc(dists, topk=0.01 * num)\n","    acc = Namespace(num=len(dists), tp1=tp1, tp5=tp5, tp10=tp10, tp1p=tp1p)\n","\n","    log_print('\\nEvaluate Samples:{num:d}\\nRecall(p2s/s2p) tp1:{tp1[0]:.2f}/{tp1[1]:.2f} ' \\\n","                'tp5:{tp5[0]:.2f}/{tp5[1]:.2f} tp10:{tp10[0]:.2f}/{tp10[1]:.2f} ' \\\n","                'tp1%:{tp1p[0]:.2f}/{tp1p[1]:.2f}'.format(epoch + 1, num=acc.num, tp1=acc.tp1,\n","                                                        tp5=acc.tp5, tp10=acc.tp10, tp1p=acc.tp1p))\n","\n","    # Save the best model\n","    tp1_p2s_acc = acc.tp1[0]\n","    if tp1_p2s_acc > ret_best_acc:\n","        ret_best_acc = tp1_p2s_acc\n","        rgan_wrapper.save_networks(epoch, os.path.dirname(log_file), best_acc=ret_best_acc, is_best=True)\n","        log_print('>>Save best model: epoch={} best_acc(tp1_p2s):{:.2f}'.format(epoch + 1, tp1_p2s_acc))\n","\n","    # Progam stastics\n","    rss, vms = get_sys_mem()\n","    log_print('Memory usage: rss={:.2f}GB vms={:.2f}GB Time:{:.2f}s'.format(rss, vms, time.time() - start_time))"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------- \n"," Namespace(b1=0.5, b2=0.999, batch_size=16, condition=1, d_model='basic', data_root='./data/CVUSA', feature_c=64, g_model='unet-skip', gan_loss='vanilla', gpu_ids='0', hard_decay1_topk_ratio=0.1, hard_decay2_topk_ratio=0.05, hard_decay3_topk_ratio=0.01, hard_topk_ratio=1.0, input_c=3, isTrain=True, lambda=10, lambda_gp=10, lambda_l1=100, lambda_ret1=1000, lambda_sm=10, lr_d=0.0001, lr_g=0.0001, lr_r=0.0001, n_critic=1, n_epochs=10, n_layers=3, name='', phase='train', polar=True, r_model='SAFA', realout_c=3, results_dir='./output', resume=True, rgan_checkpoint=None, save_step=10, seed=10, segout_c=3, start_epoch=0, train_csv='train-19zl-10.csv', val_csv='val-19zl-3.csv')\n","----------------- Options ---------------\n","                       b1: 0.5                           \n","                       b2: 0.999                         \n","               batch_size: 16                            \n","                condition: 1                             \n","                  d_model: basic                         \n","                data_root: ./data/CVUSA                  \n","                feature_c: 64                            \n","                  g_model: unet-skip                     \n","                 gan_loss: vanilla                       \n","                  gpu_ids: 0                             \n","   hard_decay1_topk_ratio: 0.1                           \n","   hard_decay2_topk_ratio: 0.05                          \n","   hard_decay3_topk_ratio: 0.01                          \n","          hard_topk_ratio: 1.0                           \n","                  input_c: 3                             \n","                  isTrain: True                          \n","                   lambda: 10                            \n","                lambda_gp: 10                            \n","                lambda_l1: 100                           \n","              lambda_ret1: 1000                          \n","                lambda_sm: 10                            \n","                     lr_d: 0.0001                        \n","                     lr_g: 0.0001                        \n","                     lr_r: 0.0001                        \n","                 n_critic: 1                             \n","                 n_epochs: 10                            \n","                 n_layers: 3                             \n","                     name:                               \n","                    phase: train                         \n","                    polar: True                          \n","                  r_model: SAFA                          \n","                realout_c: 3                             \n","              results_dir: ./output                      \n","                   resume: True                          \n","          rgan_checkpoint: None                          \n","                save_step: 10                            \n","                     seed: 10                            \n","                 segout_c: 3                             \n","              start_epoch: 0                             \n","                train_csv: train-19zl-10.csv             \n","                  val_csv: val-19zl-3.csv                \n","----------------- End -------------------\n","Init SAFA as retrieval model\n","Load data from ./data/CVUSA/splits/train-19zl-10.csv, total 10\n","Dataset object has been loaded!\n","Load data from ./data/CVUSA/splits/val-19zl-3.csv, total 3\n","Dataset object has been loaded!\n","Load datasets from ./data/CVUSA: train_set=3 val_set=3\n","Start training from epoch 0 to 10, best acc: 0.0\n",">>> RGAN Epoch 0\n","Batch:1 loss=0.664 samples:3 tp1=33.33/33.33 tp5=100.00/100.00\n","\n","Evaluate Samples:3\n","Recall(p2s/s2p) tp1:33.33/33.33 tp5:100.00/100.00 tp10:100.00/100.00 tp1%:33.33/33.33\n",">>Save best model: epoch=1 best_acc(tp1_p2s):33.33\n","Memory usage: rss=3.10GB vms=42.70GB Time:3.12s\n",">>> RGAN Epoch 1\n","Batch:1 loss=0.333 samples:3 tp1=100.00/100.00 tp5=100.00/100.00\n","\n","Evaluate Samples:3\n","Recall(p2s/s2p) tp1:66.67/66.67 tp5:100.00/100.00 tp10:100.00/100.00 tp1%:66.67/66.67\n",">>Save best model: epoch=2 best_acc(tp1_p2s):66.67\n","Memory usage: rss=3.10GB vms=42.70GB Time:3.02s\n",">>> RGAN Epoch 2\n","Batch:1 loss=0.168 samples:3 tp1=100.00/100.00 tp5=100.00/100.00\n","\n","Evaluate Samples:3\n","Recall(p2s/s2p) tp1:66.67/66.67 tp5:100.00/100.00 tp10:100.00/100.00 tp1%:66.67/66.67\n","Memory usage: rss=3.10GB vms=42.70GB Time:1.98s\n",">>> RGAN Epoch 3\n","Batch:1 loss=0.070 samples:3 tp1=100.00/100.00 tp5=100.00/100.00\n","\n","Evaluate Samples:3\n","Recall(p2s/s2p) tp1:100.00/100.00 tp5:100.00/100.00 tp10:100.00/100.00 tp1%:100.00/100.00\n",">>Save best model: epoch=4 best_acc(tp1_p2s):100.00\n","Memory usage: rss=3.10GB vms=42.70GB Time:3.01s\n",">>> RGAN Epoch 4\n","Batch:1 loss=0.015 samples:3 tp1=100.00/100.00 tp5=100.00/100.00\n","\n","Evaluate Samples:3\n","Recall(p2s/s2p) tp1:100.00/100.00 tp5:100.00/100.00 tp10:100.00/100.00 tp1%:100.00/100.00\n","Memory usage: rss=3.10GB vms=42.70GB Time:1.96s\n",">>> RGAN Epoch 5\n","Batch:1 loss=0.002 samples:3 tp1=100.00/100.00 tp5=100.00/100.00\n","\n","Evaluate Samples:3\n","Recall(p2s/s2p) tp1:100.00/100.00 tp5:100.00/100.00 tp10:100.00/100.00 tp1%:100.00/100.00\n","Memory usage: rss=3.10GB vms=42.70GB Time:1.97s\n",">>> RGAN Epoch 6\n","Batch:1 loss=0.000 samples:3 tp1=100.00/100.00 tp5=100.00/100.00\n","\n","Evaluate Samples:3\n","Recall(p2s/s2p) tp1:100.00/100.00 tp5:100.00/100.00 tp10:100.00/100.00 tp1%:100.00/100.00\n","Memory usage: rss=3.10GB vms=42.70GB Time:5.26s\n",">>> RGAN Epoch 7\n","Batch:1 loss=0.000 samples:3 tp1=100.00/100.00 tp5=100.00/100.00\n","\n","Evaluate Samples:3\n","Recall(p2s/s2p) tp1:100.00/100.00 tp5:100.00/100.00 tp10:100.00/100.00 tp1%:100.00/100.00\n","Memory usage: rss=3.10GB vms=42.70GB Time:5.46s\n",">>> RGAN Epoch 8\n","Batch:1 loss=0.000 samples:3 tp1=100.00/100.00 tp5=100.00/100.00\n","\n","Evaluate Samples:3\n","Recall(p2s/s2p) tp1:100.00/100.00 tp5:100.00/100.00 tp10:100.00/100.00 tp1%:100.00/100.00\n","Memory usage: rss=3.10GB vms=42.70GB Time:3.83s\n",">>> RGAN Epoch 9\n","Batch:1 loss=0.000 samples:3 tp1=100.00/100.00 tp5=100.00/100.00\n","\n","Evaluate Samples:3\n","Recall(p2s/s2p) tp1:100.00/100.00 tp5:100.00/100.00 tp10:100.00/100.00 tp1%:100.00/100.00\n","Memory usage: rss=3.10GB vms=42.70GB Time:9.69s\n"]}]},{"cell_type":"markdown","metadata":{"id":"LPORp7_oygHA"},"source":["### First run: around 2hrs and 20min -> banned between batch 320 (5120 image) and 360 (5760 image)\n","\n","RGAN Epoch 0\n","Batch:40 loss=0.227 samples:640 tp1=26.41/26.56 tp5=47.34/49.69\n","\n","Batch:80 loss=0.138 samples:640 tp1=48.91/49.53 tp5=76.88/77.66\n","\n","Batch:120 loss=0.105 samples:640 tp1=59.38/62.34 tp5=84.53/85.16\n","\n","Batch:160 loss=0.084 samples:640 tp1=57.19/54.84 tp5=81.41/83.91\n","\n","Batch:200 loss=0.071 samples:640 tp1=64.22/65.31 tp5=86.09/86.72\n","\n","Batch:240 loss=0.062 samples:640 tp1=67.50/67.19 tp5=88.75/89.84\n","\n","Batch:280 loss=0.056 samples:640 tp1=70.31/70.16 tp5=90.16/89.22\n","\n","Batch:320 loss=0.051 samples:640 tp1=68.59/68.75 tp5=90.47/91.41"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_jQzVz-KSTnP","executionInfo":{"status":"ok","timestamp":1639235915849,"user_tz":-60,"elapsed":9285,"user":{"displayName":"Silent Storm","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18222167859692415426"}},"outputId":"71184ff5-c9b9-4240-c531-ed6820724c26"},"source":["# check if an image can be found in our data folder\n","# if this throws a timeout (2min) than the dataloader probably won't work either\n","# try to run it until it works\n","!ls 'data/CVUSA/polarmap/' | grep \"0041073\""],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["0041073.jpg\n"]}]},{"cell_type":"markdown","metadata":{"id":"NcP5_sE-IA4q"},"source":["### Test model"]},{"cell_type":"code","metadata":{"id":"q0eeAI4CIA4q"},"source":["parse = parser.Parser()\n","opt, log_file = parse.parse()\n","opt.is_Train = True\n","make_deterministic(opt.seed)\n","os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(x) for x in opt.gpu_ids)\n","\n","log = open(log_file, 'a')\n","log_print = lambda ms: parse.log(ms, log)\n","\n","#define networks\n","generator = define_G(netG=opt.g_model, gpu_ids=opt.gpu_ids)\n","print('Init {} as generator model'.format(opt.g_model))\n","\n","discriminator = define_D(input_c=opt.input_c, output_c=opt.realout_c, ndf=opt.feature_c, netD=opt.d_model,\n","                            condition=opt.condition, n_layers_D=opt.n_layers, gpu_ids=opt.gpu_ids)\n","print('Init {} as discriminator model'.format(opt.d_model))\n","\n","retrieval = define_R(ret_method=opt.r_model, polar=opt.polar, gpu_ids=opt.gpu_ids)\n","print('Init {} as retrieval model'.format(opt.r_model))\n","\n","# Initialize network wrapper\n","if opt.resume:\n","    opt.rgan_checkpoint = os.path.join('./placeholder_checkpoint_path', 'rgan_best_ckpt.pth')\n","\n","rgan_wrapper = rgan_wrapper.RGANWrapper(opt, log_file, generator, discriminator, retrieval)\n","# Configure data loader\n","val_dataset = CVUSA(root=opt.data_root, csv_file=opt.val_csv, use_polar=opt.polar, name=opt.name,\n","                    transform_op=ToTensor())\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=opt.batch_size, shuffle=False, num_workers=0)\n","\n","log_print('Load test dataset from {}: val_set={}'.format(opt.data_root, len(val_dataset)))\n","log_print('length of val loader: {:d}'.format(len(val_loader)))\n","\n","rgan_wrapper.generator.eval()\n","rgan_wrapper.retrieval.eval()\n","fake_street_batches_v = []\n","street_batches_v = []\n","item_ids = []\n","\n","for i, data in enumerate(val_loader):\n","    print (i)\n","    rgan_wrapper.set_input(data)\n","    rgan_wrapper.eval_model()\n","    fake_street_batches_v.append(rgan_wrapper.fake_street_out_val.cpu().data)\n","    street_batches_v.append(rgan_wrapper.street_out_val.cpu().data)\n","\n","fake_street_vec = torch.cat(fake_street_batches_v, dim=0)\n","street_vec = torch.cat(street_batches_v, dim=0)\n","dists = 2 - 2 * torch.matmul(fake_street_vec, street_vec.permute(1, 0))\n","\n","tp1 = rgan_wrapper.mutual_topk_acc(dists, topk=1)\n","tp5 = rgan_wrapper.mutual_topk_acc(dists, topk=5)\n","tp10 = rgan_wrapper.mutual_topk_acc(dists, topk=10)\n","\n","num = len(dists)\n","tp1p = rgan_wrapper.mutual_topk_acc(dists, topk=0.01 * num)\n","acc = Namespace(num=len(dists), tp1=tp1, tp5=tp5, tp10=tp10, tp1p=tp1p)\n","\n","log_print('\\nEvaluate Samples:{num:d}\\nRecall(p2s/s2p) tp1:{tp1[0]:.2f}/{tp1[1]:.2f} ' \\\n","        'tp5:{tp5[0]:.2f}/{tp5[1]:.2f} tp10:{tp10[0]:.2f}/{tp10[1]:.2f} ' \\\n","        'tp1%:{tp1p[0]:.2f}/{tp1p[1]:.2f}'.format(1, num=acc.num, tp1=acc.tp1,\n","                                                tp5=acc.tp5, tp10=acc.tp10, tp1p=acc.tp1p))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w6CKmw4rIA4r"},"source":[""],"execution_count":null,"outputs":[]}]}